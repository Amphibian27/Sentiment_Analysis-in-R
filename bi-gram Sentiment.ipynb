{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import stop_words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\Downloads\\Engage_V1.0.csv',encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_clean'] = df['Description'].str.lower()\n",
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: re.sub('[^a-zA-Z0-9#.:-_]',' ',row))\n",
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: re.sub('[+>\\/<,)Â¿(&?:?%*=-]+','',row))\n",
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: re.sub('\\s+[.]','',row))\n",
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: re.sub('\\d+','',row))\n",
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: re.sub('http\\S','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl =  WordNetLemmatizer()\n",
    "df['desc_clean']  = df['desc_clean'].apply(lambda row: wnl.lemmatize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        for amarpatan region of madhya pradesh  we wis...\n",
       "1        consumer called up and asked about if he can g...\n",
       "2        consumer called up as he has a pack of nestl  ...\n",
       "3        retailer called in again and said that his con...\n",
       "4        consumer called to inquire about the method of...\n",
       "5        consumer called up as he wanted to know about ...\n",
       "6        consumer called us and shared the feedback for...\n",
       "7        consumer called in as she is using high protei...\n",
       "8        source nestle com   firstname sharad  lastname...\n",
       "9        customer is looking for a technician for two v...\n",
       "10       consumer called to inquire about the shelf lif...\n",
       "11       source nestle com   firstname jay  lastname de...\n",
       "12       consumer is looking for technician for nns ven...\n",
       "13       hi gudevening   iam nishan karkera here  at pr...\n",
       "14       customer called up as he want distributorship ...\n",
       "15       consumer is looking for a technician as she sa...\n",
       "16       consumer called saying that he is feeding lact...\n",
       "17        dear sir     i am  d durai murugan    manufac...\n",
       "18       consumer called in to inquire about the availa...\n",
       "19       consumer concern  consumer called and inquired...\n",
       "20       sub  resume for requirement   dear sir     i a...\n",
       "21       we are not receiving the supply of nestle item...\n",
       "22       kindly change your latest maggi tv commercial ...\n",
       "23       sub  regarding getting distributorship or whol...\n",
       "24       customer called us and said that he wants dist...\n",
       "25       dear sir madam    came to know about your new ...\n",
       "26       sub  availability of maggi  dear sir madam   i...\n",
       "27       consumer called and inquired if nestle manufac...\n",
       "28                                       unproductive call\n",
       "29       consumer called up as he wanted to know about ...\n",
       "                               ...                        \n",
       "16603    @nestleindia bought this today at chennai  and...\n",
       "16604    hi nestle team i am your regular customer who ...\n",
       "16605    my daughter bought me a jar of  nescafe classi...\n",
       "16606    consumer concern consumer called in and was sa...\n",
       "16607    consumer concern called to consumer  and menti...\n",
       "16608    dear nestle    very sadly informing to you abo...\n",
       "16609    wat the hell is this put some care to make thi...\n",
       "16610    this is to bring to your notice about the poor...\n",
       "16611      consumer concern consumer called up and said...\n",
       "16612    hai  please find the attached images of uneven...\n",
       "16613    consumer concern retailer called  and he menti...\n",
       "16614    ma april  b  w cb  april  g ma april  b  ma ap...\n",
       "16615    dear nestle india    i purchased a quality str...\n",
       "16616    consumer s concern  consumer called in with a ...\n",
       "16617    dear nestle team   one of our customer has pur...\n",
       "16618    dear           we are a regular customer of na...\n",
       "16619    consumer concern consumer complained for kitka...\n",
       "16620    we have received and delivered  a full case of...\n",
       "16621    consumer concern consumer called in and stated...\n",
       "16622    hi    recently i purchased nan excella pro  fr...\n",
       "16623    source nestle com   firstname nelson  lastname...\n",
       "16624    from lanney tanya chennai branch control [mail...\n",
       "16625    hello   i bought  gm pack of nescafe classic f...\n",
       "16626    consumer concern consumer called in for the co...\n",
       "16627    consumer concern consumer called up as he went...\n",
       "16628    dear guys    i have no idea whats happened to ...\n",
       "16629    to nestle consumer care   respected sir  i bou...\n",
       "16630    hi team this is to bring your kind considerati...\n",
       "16631    we buy wheat apple to feed my baby he likes th...\n",
       "16632                            shortage in intact carton\n",
       "Name: desc_clean, Length: 16633, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['desc_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_clean'] = df['desc_clean'].apply(lambda row:  re.split(r' ',row)).apply(lambda row: list(filter(None,row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = nltk.corpus.stopwords.words('english')\n",
    "combine_list = [word for word in stop_words.get_stop_words('en') if word not in nltk.corpus.stopwords.words('english')]\n",
    "stoplist.extend(combine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_clean'] = df['desc_clean'].apply(lambda row: [word for word in row if word not in stoplist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [amarpatan, region, madhya, pradesh, wish, nes...\n",
       "1        [consumer, called, asked, give, nestogen, mont...\n",
       "2        [consumer, called, pack, nestl, cerelac, wheat...\n",
       "3        [retailer, called, said, concern, registered, ...\n",
       "4        [consumer, called, inquire, method, preparatio...\n",
       "5        [consumer, called, wanted, know, expiration, d...\n",
       "6        [consumer, called, us, shared, feedback, nestl...\n",
       "7        [consumer, called, using, high, protein, resou...\n",
       "8        [source, nestle, com, firstname, sharad, lastn...\n",
       "9        [customer, looking, technician, two, vending, ...\n",
       "10       [consumer, called, inquire, shelf, life, maggi...\n",
       "11       [source, nestle, com, firstname, jay, lastname...\n",
       "12       [consumer, looking, technician, nns, vending, ...\n",
       "13       [hi, gudevening, iam, nishan, karkera, present...\n",
       "14       [customer, called, want, distributorship, area...\n",
       "15       [consumer, looking, technician, said, still, n...\n",
       "16       [consumer, called, saying, feeding, lactogen, ...\n",
       "17       [dear, sir, durai, murugan, manufacturing, exc...\n",
       "18       [consumer, called, inquire, availability, nest...\n",
       "19       [consumer, concern, consumer, called, inquired...\n",
       "20       [sub, resume, requirement, dear, sir, durai, m...\n",
       "21       [receiving, supply, nestle, item, cerelac, cho...\n",
       "22       [kindly, change, latest, maggi, tv, commercial...\n",
       "23       [sub, regarding, getting, distributorship, who...\n",
       "24       [customer, called, us, said, wants, distributo...\n",
       "25       [dear, sir, madam, came, know, new, puppy, foo...\n",
       "26       [sub, availability, maggi, dear, sir, madam, h...\n",
       "27       [consumer, called, inquired, nestle, manufactu...\n",
       "28                                    [unproductive, call]\n",
       "29       [consumer, called, wanted, know, expiration, d...\n",
       "                               ...                        \n",
       "16603    [@nestleindia, bought, today, chennai, chocola...\n",
       "16604    [hi, nestle, team, regular, customer, consumes...\n",
       "16605    [daughter, bought, jar, nescafe, classic, open...\n",
       "16606    [consumer, concern, consumer, called, saying, ...\n",
       "16607    [consumer, concern, called, consumer, mentione...\n",
       "16608    [dear, nestle, sadly, informing, product, whea...\n",
       "16609    [wat, hell, put, care, make, product, please, ...\n",
       "16610    [bring, notice, poor, quality, packing, nestle...\n",
       "16611    [consumer, concern, consumer, called, said, pu...\n",
       "16612    [hai, please, find, attached, images, uneven, ...\n",
       "16613    [consumer, concern, retailer, called, mentione...\n",
       "16614    [april, b, w, cb, april, g, april, b, april, b...\n",
       "16615    [dear, nestle, india, purchased, quality, stre...\n",
       "16616    [consumer, concern, consumer, called, complain...\n",
       "16617    [dear, nestle, team, one, customer, purchased,...\n",
       "16618    [dear, regular, customer, nan, pro, past, mont...\n",
       "16619    [consumer, concern, consumer, complained, kitk...\n",
       "16620    [received, delivered, full, case, slim, milk, ...\n",
       "16621    [consumer, concern, consumer, called, stated, ...\n",
       "16622    [hi, recently, purchased, nan, excella, pro, o...\n",
       "16623    [source, nestle, com, firstname, nelson, lastn...\n",
       "16624    [lanney, tanya, chennai, branch, control, [mai...\n",
       "16625    [hello, bought, gm, pack, nescafe, classic, re...\n",
       "16626    [consumer, concern, consumer, called, concern,...\n",
       "16627    [consumer, concern, consumer, called, went, ma...\n",
       "16628    [dear, guys, idea, whats, happened, quality, c...\n",
       "16629    [nestle, consumer, care, respected, sir, bough...\n",
       "16630    [hi, team, bring, kind, consideration, yesterd...\n",
       "16631    [buy, wheat, apple, feed, baby, likes, flavour...\n",
       "16632                           [shortage, intact, carton]\n",
       "Name: desc_clean, Length: 16633, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['desc_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_clean'] = df['desc_clean'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrm = df['desc_clean'].apply(lambda row: nltk.bigrams(row.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df['desc_clean'], bigrm, random_state = 42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))\n",
    "X_train = cv.fit_transform(df['desc_clean'])\n",
    "X_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-09eff9b5395e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Converting sparse training and testing datasets to dense matrices for classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Classification using Multinomial Naive Bayes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mtodense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \"\"\"\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Converting sparse training and testing datasets to dense matrices for classification\n",
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()\n",
    "#Classification using Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "prediction = classifier.predict(X_test)\n",
    "accuracy_score(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16633, 26)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
