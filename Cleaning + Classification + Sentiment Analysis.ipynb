{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re \n",
    "from ast import literal_eval\n",
    "from random import seed,sample,choice\n",
    "from itertools import chain\n",
    "import multiprocessing\n",
    "from nltk.tokenize import word_tokenize,WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import string\n",
    "import stop_words\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.corpus.util\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\Desktop\\train_.csv',encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentiment', 'Sound Bite Text',\n",
       "       'soundBites_with_hashtags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'text':'Sound Bite Text'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4626"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of Dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1887"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of rows containing text data\n",
    "len(df[df[\"Sound Bite Text\"].isna() == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rows not containing any text data\n",
    "len(df[df[\"Sound Bite Text\"].isna() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Sound Bite Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentiment, Sound Bite Text]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Sound Bite Text\"].isna() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Removing Hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rows not containing text data in \"Sound Bite Text\" column are dropped.\n",
    "df.drop(df[df[\"Sound Bite Text\"].isna() == True].index.values,axis = 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sentiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sentiments'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-b97c795e3c5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sentiments'"
     ]
    }
   ],
   "source": [
    "df = df.loc[df[df['Sentiments'].isna() == False].index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating seperate column for cleaned data(Without Hashtags)\n",
    "df[\"soundBites\"] = df[\"Sound Bite Text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Hashtags\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: re.sub(r'@[A-Z0-9a-z_]+', '',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites'] = df[\"soundBites\"].apply(lambda row: re.sub('[^a-zA-Z0-9#-_]',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites'] = df['soundBites'].apply(lambda row: re.sub('#\\w+',' ',row))\n",
    "df['soundBites'] = df['soundBites'].apply(lambda row: re.sub('[â❤]',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Non-words\n",
    "df['soundBites'] = df[\"soundBites\"].apply(lambda row: re.sub('[;+>\\/<,.)¿(&?:?%*=-]+','',row))\n",
    "#df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: re.sub('\\W+',\" \",row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing URLs\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: re.sub('http\\S+','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       anything new could\n",
       "1                                              little girl\n",
       "2                  chicken noodles sold india halal please\n",
       "3                                extreme affinity products\n",
       "4                     follow follow us n promote us follow\n",
       "5        tweet brasilia reuters brazilian agriculture m...\n",
       "6        speaking congressional hearing tuesday said es...\n",
       "7        pocket friendly cafe hangout folks serving uni...\n",
       "8        beets pexelspixabay beets fiery deep color red...\n",
       "9                                                         \n",
       "10                                                        \n",
       "11       reporting thomas mukoya george obulutsa duncan...\n",
       "12       # hv never anything family biggest fan ur v ma...\n",
       "13       place offers variety paranthas omelettes pasta...\n",
       "14                                              april meri\n",
       "15       noodles probably ultimate solution anytime kin...\n",
       "16                                           yummy looking\n",
       "17       point mussorie points total hit amongst everyo...\n",
       "18       oddly points might wanna hault hitting destina...\n",
       "19                                                  cheese\n",
       "20       never really knew could taste good cheese top ...\n",
       "21            well morning planned go voyage early morning\n",
       "22                           trust say bowl hit truck left\n",
       "23                                          go slurp bowls\n",
       "24                                                        \n",
       "25       dhiyaan se dekho earphone lagake lit bit thing...\n",
       "26                                                        \n",
       "27                              saved tummy wolves unusual\n",
       "28       medical student assure completely healthy tast...\n",
       "29       perfect dear win u dear first tym ruchika anan...\n",
       "                               ...                        \n",
       "14997                                          sizzler foi\n",
       "15007                                                     \n",
       "15013                                     grilled sandwich\n",
       "15016                                     cheesey nd yummy\n",
       "15022    yummyyyy paneer cheese pizzas delicious pizza ...\n",
       "15048                                                     \n",
       "15059                                                     \n",
       "15064                                                     \n",
       "15068                                                     \n",
       "15070                                yummy mom preparation\n",
       "15082                                                     \n",
       "15099                          follow follow follow follow\n",
       "15128                                              monsoon\n",
       "15143                             isko follow b kar frands\n",
       "15145                               rain best combinations\n",
       "15157    good creamy eat billu's hut netaji subhash pla...\n",
       "15158                                        today magical\n",
       "15160                                                    #\n",
       "15161                                                     \n",
       "15167    best put smile husband face giving wings peopl...\n",
       "15168                                           thank much\n",
       "15169                                   # yummy daughter #\n",
       "15171                                            # # # # #\n",
       "15172                                    best n testy ever\n",
       "15181    course provider udemy course instructor osama ...\n",
       "15187                                                     \n",
       "15199                       vegetable freezing cold best u\n",
       "15205                                                  tag\n",
       "15211                                                     \n",
       "15218                                                     \n",
       "Name: soundBites, Length: 4133, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['soundBites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Digits\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: re.sub('\\d+',\" \",row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites'] = df[\"soundBites\"].apply(lambda row: re.sub(r'\\w+(.)$',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites'] = df[\"soundBites\"].apply(lambda row: re.sub(r'\\s+[.]',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites'] = df['soundBites'].apply(lambda row: row.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the empty strings from the list of tokens\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: list(filter(None,row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of stopwords\n",
    "stopword = set(stopwords.words('english'))\n",
    "stop_list = set(['maggi','maggie','also','nc','rz','njc','like','cz','gonna','carolina','garmin',\n",
    "                 'screenshot','team','wish','provide','screen','rzd','moq','cgof','pcs','kis','ko','rt','customer','called',\n",
    "                'informed','consumer'])\n",
    "stopword.update(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from tokens\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row :[item for item in row if item not in stopword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soundBites']  = df['soundBites'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "df[\"soundBites\"] = df[\"soundBites\"].apply(lambda row: wnl.lemmatize(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning (including hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#including Hashtags\n",
    "df['soundBites_with_hashtags'] = df['Sound Bite Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing words not containing characters,hashtags or underscores\n",
    "df['soundBites_with_hashtags'] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('[^a-zA-Z0-9#-_]',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing handles\n",
    "df['soundBites_with_hashtags'] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('@[a-zA-Z0-9_]+',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Noise\n",
    "df['soundBites_with_hashtags'] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('[;+>.\\/<,)❤☕₹⛩(&?:!%*=-]+','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise Removal\n",
    "df['soundBites_with_hashtags'] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('_{2,}','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise Removal\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('Â\\x92',\"\\'\",row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise Removal\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('Â\\x91',\"\\'\",row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing URLs\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('http\\S+','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       rt   'congrats to   mary sotos   for green pow...\n",
       "1       pop up #bostonholiday  #urbannutcracker's   am...\n",
       "2       new 4inch iphone 6 reported 5 reasons apple mu...\n",
       "3         gbp200 repair an #iphone5 that died 4 mths o...\n",
       "4       foreign currency exchange may be a headwind fo...\n",
       "5       mark #zuckerberg slams tim #cook you don't car...\n",
       "6           i can't say enough about how awesome apple...\n",
       "7         #samsung #appeals $930m fine in   [#apple] #...\n",
       "8                           block trade detected in #aapl\n",
       "9       is apple inc losing the $5 billion edtech mark...\n",
       "10      any one know how to retrieve deleted texts fro...\n",
       "11      apple  fibonacci technicals levels  intraday  ...\n",
       "12          #aaplapple is building a $161 million theatre\n",
       "13      mark #zuckerberg slams tim #cook you're not in...\n",
       "14      apple begins hiring for first belgian retail s...\n",
       "15      apple launches ten holidaythemed itunes radio ...\n",
       "16            'deleted #ipod #music from rival services' \n",
       "17      apple throws lastminute curve ball in lawsuit ...\n",
       "18      3 reasons #apple is a potential warren buffett...\n",
       "19      is #apple inc losing the $5 billion edtech mar...\n",
       "20      apple intraday comments  updated range  premiu...\n",
       "21      attn     buy these guys amp make #appletv what...\n",
       "22        excellent customer service thanks ian #apple...\n",
       "23      here are some of the satellites  1  1  3  1  1...\n",
       "24        why i cannot alttab back to full screen app ...\n",
       "25              to host free #coding workshops in stores \n",
       "26      #apple begins hiring retail positions in bruss...\n",
       "27      apple  fibonacci technicals levels  intraday  ...\n",
       "28      rt   studio at 45000 ft  one outlet  4 compute...\n",
       "29        awards   with distinguished school honor    ...\n",
       "                              ...                        \n",
       "1860    apple is warming up to social media apple is h...\n",
       "1861    apple is warming up to social media apple is h...\n",
       "1862    apple is warming up to social media apple is h...\n",
       "1863    apple is warming up to social media apple is h...\n",
       "1864    apple is warming up to social media apple is h...\n",
       "1865    apple is warming up to social media apple is h...\n",
       "1866    apple is warming up to social media apple is h...\n",
       "1867    apple is warming up to social media apple is h...\n",
       "1868    apple is warming up to social media apple is h...\n",
       "1869    apple is warming up to social media apple is h...\n",
       "1870    apple is warming up to social media apple is h...\n",
       "1871    apple is warming up to social media apple is h...\n",
       "1872    apple is warming up to social media apple is h...\n",
       "1873    apple is warming up to social media apple is h...\n",
       "1874    apple is warming up to social media apple is h...\n",
       "1875    apple is warming up to social media apple is h...\n",
       "1876    apple is warming up to social media apple is h...\n",
       "1877    apple is warming up to social media apple is h...\n",
       "1878    being held hostage at    they are replacing th...\n",
       "1879    rt   love the   is supporting #hourofcode with...\n",
       "1880    tim cook met with jesse jackson for 'positive ...\n",
       "1881    hey   is it normal for my laptop charger to be...\n",
       "1882    via fc apple is warming up to social media  ap...\n",
       "1883       rt   there is no avocado emoji may i ask why  \n",
       "1884      i could not agree more between     and   onl...\n",
       "1885    my iphone 5's photos are no longer downloading...\n",
       "1886    rt   we're so excited to be named to  's 'app ...\n",
       "1887                             just got the iphone 6   \n",
       "1888    rt   can   survive the 2014 holiday investors ...\n",
       "1889    major crisis avoided   you guys were able to r...\n",
       "Name: soundBites_with_hashtags, Length: 1890, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['soundBites_with_hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Full-Stops\n",
    "df['soundBites_with_hashtags'] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub(r'[.]$',' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing dates and digits\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: re.sub('\\d+','',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Maggi Only\n",
    "df['soundBites_with_hashtags'] = df['soundBites_with_hashtags'].apply(lambda row: row.replace('-Minute','2-Minute'))\n",
    "df['soundBites_with_hashtags'] = df['soundBites_with_hashtags'].apply(lambda row: row.replace('-minute','2-Minute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating joined Hastags\n",
    "df['soundBites_with_hashtags'] = df['soundBites_with_hashtags'].apply(lambda row: re.split(r'(#\\w+)',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the terms in a document\n",
    "df['soundBites_with_hashtags'] = df['soundBites_with_hashtags'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "wnl = WordNetLemmatizer()\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: wnl.lemmatize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting for filteration\n",
    "df['soundBites_with_hashtags'] = df['soundBites_with_hashtags'].apply(lambda row: re.split(r' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the empty strings from the list of tokens\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: list(filter(None,row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Stopwords\n",
    "stopword = set(stopwords.words('english'))\n",
    "stopword_update = [item for item in stop_words.get_stop_words('en') if item not in nltk.corpus.stopwords.words('english')]\n",
    "stop_list = set(['maggi','maggie','#maggi','#maggie','also','njc','nc','rz','use','like','carolina','food','love','garmin','new',\n",
    "                 'raha','pm','tags','pak','across','ki','hi','screenshot','team','wish','provide','screen',\n",
    "                 'pictwittercomclsauwtd',\n",
    "                 '#foodie','#instafood','#foodblogger','tag','rt','updates','reuters','#fooddiaries','#foodisbae','#foodography',\n",
    "                '#likeforlike','#followforfollow','follow','join','rs','#foodlove','delicious','#foodgasm','#foodielife','simpsons'\n",
    "                 '#foodblogger','#merimaggie','#merimaggi','try','#indianblogger','#maggilove','#njcs','#maggielove','#foodporn',\n",
    "                '#food','#foodie','#foodporn','#zomato','#maniamaggi','#tastymaggi','#maniamaggie','#tastymaggie','hai','u','km',\n",
    "                 'tasty','yummy','#yummylicious','#yummilicious','#foddy','#foodgram','#maggilover','#maggielover','#tasty','rda',\n",
    "                 '#yummy','#foddie','#swiggyindia','#zomatoindia','#swiggy','#foodstagram','#instagood','#indianfood','#likelike',\n",
    "                 '#love','#delicious','#foodlover,''#picoftheday'',#noodles','#eeeats','#eeeeeats','#foodpics','#picoftheday',\n",
    "                'noodles','#sodelhi','#likelike','#nomnom','#buzzfoodfeed','#fgram','#eatingforinsta','#saadidilli','kuch',\n",
    "                '#saddidilli','#ll','#flt','#foodphotography','#foodtalkindia','#delhifoodie','#foodlover','#maggilovers',\n",
    "                '#maggielovers','#foodtalkindia','#delhifoodblogger','#delhigram','#instagram','#instagood','#photooftheday',\n",
    "                '#instadaily','#followfollow','#fgrams','#streetfood','#igers','#','#iger','#followme','#foodies','#likes',\n",
    "                 '#instalike','#instalike','#indianfoodbloggers','indianfoodblogger','#foodshot','#foodcoma','gunsmoke','#noodles',\n",
    "                '#vscodelhi','#foodblog','#foodiegram','#foodphoto','#delhi_igers','#delhifood','#delhidiaries','#mumbaifood',\n",
    "                 '#mumbaidiaries','#foodoftheday','#indianfoodie','#foodaholic','#foods','#vscocam','#vscofood','#likeforfollow',\n",
    "                '#delhifoodie','#streetfoods','#eat','#yum','#follow','th','us','#follow','#india','#ahmedabad','#chennai','#delhi',\n",
    "                '#mumbai','#maggiloverforever','#vsco','#likesforlikes','#buzzfeedfood','#delhiblogger','#dfordelhi',\n",
    "                '#tastyfood','#foodiesofinstagram','#knowyourmaggi'])\n",
    "stopword.update(stop_list),\n",
    "stopword.update(set(stopword_update))\n",
    "stopword.update(set(string.ascii_lowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from tokens\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(lambda row: [item for item in row if item not in stopword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the terms in each Documents/\n",
    "df[\"soundBites_with_hashtags\"] = df[\"soundBites_with_hashtags\"].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to File\n",
    "df.to_csv(r'.\\Desktop\\train_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Maggi_Clean2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Classified data for training and test sets\n",
    "data = df[df['sentiment'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "data.loc[data['Sentiments'] == 'None','Sentiments'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating seperate dataset for Classification\n",
    "dataset = pd.DataFrame(data['soundBites_with_hashtags'])\n",
    "dataset['Sentiments'] = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://docs.python.org/2/library/ast.html#ast.literal_eval\n",
    "#Used to convert a string containing a list into a list\n",
    "#dataset['soundBites'] = dataset['soundBites'].apply(lambda row: literal_eval(''.join(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a string from list of tokens\n",
    "dataset['soundBites'] = dataset['soundBites'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.copy()\n",
    "dataset.rename(columns = {'Sentiment': 'Sentiments'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and testing data\n",
    "x_train,x_test,y_train,y_test = train_test_split(dataset['soundBites'],dataset['Sentiments'], random_state = 20, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying CountVectorizer to get token count\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(x_train)\n",
    "X_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying TFIDF\n",
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8898488120950324"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting sparse training and testing datasets to dense matrices for classification\n",
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()\n",
    "#Classification using Multinomial Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "prediction = classifier.predict(X_test)\n",
    "accuracy_score(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5673146148308136"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classifcation using Gaussian Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "prediction = classifier.predict(X_test)\n",
    "accuracy_score(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9006479481641468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 17,  95,   5],\n",
       "       [  9, 871,  19],\n",
       "       [  1,   9, 363]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Using Decision Tree Classifier\n",
    "clfdt = DecisionTreeClassifier(random_state = 42)\n",
    "clfdt.fit(X_train,y_train)\n",
    "prediction = clfdt.predict(X_test)\n",
    "accuracy_score(y_true = y_test,y_pred = prediction)\n",
    "print(\"Accuracy: \",accuracy_score(y_pred = prediction,y_true = y_test))\n",
    "confusion_matrix(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.912167026637869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 16,  97,   4],\n",
       "       [  0, 890,   9],\n",
       "       [  0,  12, 361]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Using Support Vector Classifier\n",
    "clfSVM = LinearSVC()\n",
    "clfSVM.fit(X_train,y_train)\n",
    "prediction = clfSVM.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_pred = prediction,y_true = y_test))\n",
    "confusion_matrix(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8984881209503239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9,  98,  10],\n",
       "       [  2, 880,  17],\n",
       "       [  0,  14, 359]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Using Random Forest Classifier\n",
    "rfclf = RandomForestClassifier(random_state = 0)\n",
    "rfclf.fit(X_train,y_train)\n",
    "prediction = rfclf.predict(X_test)\n",
    "accuracy_score(y_true = y_test, y_pred = prediction)\n",
    "print(\"Accuracy: \",accuracy_score(y_pred = prediction,y_true = y_test))\n",
    "confusion_matrix(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9136069114470843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 20,  96,   1],\n",
       "       [  0, 896,   3],\n",
       "       [  4,  16, 353]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification using XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state = 21)\n",
    "xgb.fit(X_train,y_train)\n",
    "prediction = xgb.predict(X_test)\n",
    "accuracy_score(y_true = y_test, y_pred = prediction)\n",
    "print(\"Accuracy: \",accuracy_score(y_pred = prediction,y_true = y_test))\n",
    "confusion_matrix(y_true = y_test, y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Deeplearning - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the labels to be classified\n",
    "labelEncoder = LabelEncoder()\n",
    "Y_train = labelEncoder.fit_transform(y_train)\n",
    "Y_test = labelEncoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Neutral', 'P', 'P0'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding the labels\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y_train_ = one_hot_encoder.fit_transform(Y_train.reshape(-1,1))\n",
    "Y_test_ = one_hot_encoder.transform(Y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3241/3241 [==============================] - 2s 563us/step - loss: 0.6463 - acc: 0.7877\n",
      "Epoch 2/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.2941 - acc: 0.9003\n",
      "Epoch 3/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.2481 - acc: 0.9087\n",
      "Epoch 4/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.2226 - acc: 0.9272\n",
      "Epoch 5/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.2074 - acc: 0.9324\n",
      "Epoch 6/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1975 - acc: 0.9352\n",
      "Epoch 7/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1922 - acc: 0.9358\n",
      "Epoch 8/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1888 - acc: 0.9371\n",
      "Epoch 9/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1874 - acc: 0.9367\n",
      "Epoch 10/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1877 - acc: 0.9371\n",
      "Epoch 11/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1870 - acc: 0.9371\n",
      "Epoch 12/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1855 - acc: 0.9371\n",
      "Epoch 13/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1847 - acc: 0.9371\n",
      "Epoch 14/100\n",
      "3241/3241 [==============================] - 0s 149us/step - loss: 0.1850 - acc: 0.9371\n",
      "Epoch 15/100\n",
      "3241/3241 [==============================] - 0s 144us/step - loss: 0.1842 - acc: 0.9371\n",
      "Epoch 16/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1818 - acc: 0.9371\n",
      "Epoch 17/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1835 - acc: 0.9371\n",
      "Epoch 18/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1834 - acc: 0.9371\n",
      "Epoch 19/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1836 - acc: 0.9371\n",
      "Epoch 20/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1834 - acc: 0.9371\n",
      "Epoch 21/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1842 - acc: 0.9371\n",
      "Epoch 22/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1827 - acc: 0.9371\n",
      "Epoch 23/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1831 - acc: 0.9371 0s - loss: 0.1799 - acc: 0.939\n",
      "Epoch 24/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1836 - acc: 0.9371\n",
      "Epoch 25/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1829 - acc: 0.9371\n",
      "Epoch 26/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1824 - acc: 0.9371\n",
      "Epoch 27/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1829 - acc: 0.9371\n",
      "Epoch 28/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1829 - acc: 0.9371\n",
      "Epoch 29/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1820 - acc: 0.9371\n",
      "Epoch 30/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1827 - acc: 0.9371\n",
      "Epoch 31/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1833 - acc: 0.9371\n",
      "Epoch 32/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1826 - acc: 0.9371\n",
      "Epoch 33/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 34/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1822 - acc: 0.9371\n",
      "Epoch 35/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1821 - acc: 0.9371\n",
      "Epoch 36/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 37/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1822 - acc: 0.9371\n",
      "Epoch 38/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1823 - acc: 0.9371\n",
      "Epoch 39/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1819 - acc: 0.9371\n",
      "Epoch 40/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 41/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1819 - acc: 0.9371\n",
      "Epoch 42/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1822 - acc: 0.9371\n",
      "Epoch 43/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 44/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1820 - acc: 0.9371\n",
      "Epoch 45/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 46/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 47/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 48/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 49/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 50/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 51/100\n",
      "3241/3241 [==============================] - 0s 154us/step - loss: 0.1818 - acc: 0.9371\n",
      "Epoch 52/100\n",
      "3241/3241 [==============================] - 0s 149us/step - loss: 0.1810 - acc: 0.9371\n",
      "Epoch 53/100\n",
      "3241/3241 [==============================] - 0s 144us/step - loss: 0.1818 - acc: 0.9371\n",
      "Epoch 54/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 55/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1815 - acc: 0.9371\n",
      "Epoch 56/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 57/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1821 - acc: 0.9371\n",
      "Epoch 58/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 59/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 60/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 61/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1818 - acc: 0.9371\n",
      "Epoch 62/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 63/100\n",
      "3241/3241 [==============================] - 0s 135us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 64/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 65/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 66/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 67/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 68/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 69/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1818 - acc: 0.9371\n",
      "Epoch 70/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 71/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 72/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 73/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1815 - acc: 0.9371\n",
      "Epoch 74/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1810 - acc: 0.9371\n",
      "Epoch 75/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 76/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 77/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 78/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 79/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 80/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1816 - acc: 0.9371\n",
      "Epoch 81/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1799 - acc: 0.9371\n",
      "Epoch 82/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1817 - acc: 0.9371\n",
      "Epoch 83/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 84/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1810 - acc: 0.9371\n",
      "Epoch 85/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1810 - acc: 0.9371\n",
      "Epoch 86/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 87/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 88/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 89/100\n",
      "3241/3241 [==============================] - 0s 144us/step - loss: 0.1811 - acc: 0.9371\n",
      "Epoch 90/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1814 - acc: 0.9371\n",
      "Epoch 91/100\n",
      "3241/3241 [==============================] - 0s 140us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 92/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1812 - acc: 0.9371\n",
      "Epoch 93/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 94/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1810 - acc: 0.9371\n",
      "Epoch 95/100\n",
      "3241/3241 [==============================] - 0s 130us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 96/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 97/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1813 - acc: 0.9371\n",
      "Epoch 98/100\n",
      "3241/3241 [==============================] - 0s 120us/step - loss: 0.1809 - acc: 0.9371\n",
      "Epoch 99/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1809 - acc: 0.9371\n",
      "Epoch 100/100\n",
      "3241/3241 [==============================] - 0s 125us/step - loss: 0.1814 - acc: 0.9371\n"
     ]
    }
   ],
   "source": [
    "#Deeplearning classification using Keras\n",
    "seed(0)\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim =  32, input_shape = (X_train.shape[1],),activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 4, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adagrad', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train_, batch_size = 100, epochs = 100)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-5b80e9e76805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Accuracy Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy = '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Accuracy Score + Confusion Matrix\n",
    "print('Accuracy = ',accuracy_score(y_true = Y_test, y_pred = y_pred.argmax(axis = 1)))\n",
    "print(confusion_matrix(y_true = Y_test, y_pred = y_pred.argmax(axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis \n",
    "### using nltk.vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Maggi_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning Sentiments based on Polarity Score\n",
    "for item in data['Sound Bite Text']:   \n",
    "    i = data.index.values[data['Sound Bite Text'] == item]\n",
    "    scores = analyzer.polarity_scores(item)\n",
    "    if (scores['compound'] < 0.05) & (scores['compound'] > -0.05):\n",
    "        data.loc[i,'vader_Senti'] = 'None'\n",
    "    elif scores['compound'] < -0.05:\n",
    "        data.loc[i,'vader_Senti'] = 'N'\n",
    "    elif scores['compound'] > 0.05:\n",
    "        data.loc[i,'vader_Senti'] = 'P'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification of Sentiments ( Manual Classification vs Vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels \n",
    "le = LabelEncoder()\n",
    "vader_in = le.fit_transform(data['Sentiment'])\n",
    "vader_out = le.transform(data['vader_Senti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true = vader_out, y_pred  = vader_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true = vader_out,y_pred = vader_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['vader_Senti'] == 'N','Sound Bite Text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "##### Training Data is manually classified\n",
    "##### Entire dataset is classified as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Dataset\n",
    "train = df.loc[df['sentiment'].dropna(axis = 0).index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[train['soundBites_with_hashtags'].dropna(axis = 0).index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['soundBites_with_hashtags']\n",
    "Y_train = train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test set\n",
    "X_test = df['soundBites_with_hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sparse matrix to dense matrix\n",
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "df['Decision Tree'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Classification using XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state = 21,n_jobs = cores)\n",
    "xgb.fit(X_train,Y_train)\n",
    "df['XGB'] = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Using Support Vector Classifier\n",
    "clfSVM = LinearSVC()\n",
    "clfSVM.fit(X_train,Y_train)\n",
    "df['SVM'] = clfSVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeplearning - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the labels to be classified\n",
    "labelEncoder = LabelEncoder()\n",
    "Y_train = labelEncoder.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Neutral', 'P'], dtype=object)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Sentiments'] == 'p','Sentiments'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding the labels\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y_train = one_hot_encoder.fit_transform(Y_train.reshape(-1,1))\n",
    "#Y_test_ = one_hot_encoder.transform(Y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 0s 488us/step - loss: 0.9048 - acc: 0.6712\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.5456 - acc: 0.7391\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.3765 - acc: 0.8030\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.2672 - acc: 0.9361\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.2029 - acc: 0.9497\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.1532 - acc: 0.9524\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.1228 - acc: 0.9538\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.1014 - acc: 0.9524\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0806 - acc: 0.9633\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0592 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0410 - acc: 0.9918\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0300 - acc: 0.9946\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0216 - acc: 0.9946\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0206 - acc: 0.9959\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0156 - acc: 0.9959\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0124 - acc: 0.9959\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0117 - acc: 0.9973\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0107 - acc: 0.9959\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0096 - acc: 0.9959\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0090 - acc: 0.9973\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0087 - acc: 0.9959\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0085 - acc: 0.9959\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0072 - acc: 0.9973\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0076 - acc: 0.9959\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0076 - acc: 0.9959\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0075 - acc: 0.9959\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 0s 131us/step - loss: 0.0065 - acc: 0.9973\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0071 - acc: 0.9959\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0057 - acc: 0.9973\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0068 - acc: 0.9959\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0069 - acc: 0.9959\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0071 - acc: 0.9973\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0070 - acc: 0.9946\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0066 - acc: 0.9959\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0063 - acc: 0.9973\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0064 - acc: 0.9973\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0065 - acc: 0.9946\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0063 - acc: 0.9946\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0056 - acc: 0.9973\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9959\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0059 - acc: 0.9973\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0070 - acc: 0.9959\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0060 - acc: 0.9973\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0059 - acc: 0.9959\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0057 - acc: 0.9946\n",
      "Epoch 47/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0052 - acc: 0.9973\n",
      "Epoch 48/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0057 - acc: 0.9973\n",
      "Epoch 49/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9973\n",
      "Epoch 50/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9959\n",
      "Epoch 51/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9959\n",
      "Epoch 52/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 53/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0055 - acc: 0.9973\n",
      "Epoch 54/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0058 - acc: 0.9946\n",
      "Epoch 55/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9959\n",
      "Epoch 56/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0057 - acc: 0.9946\n",
      "Epoch 57/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0054 - acc: 0.9946\n",
      "Epoch 58/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0062 - acc: 0.9973\n",
      "Epoch 59/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0056 - acc: 0.9946\n",
      "Epoch 60/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0055 - acc: 0.9973\n",
      "Epoch 61/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0054 - acc: 0.9959\n",
      "Epoch 62/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 63/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0056 - acc: 0.9973\n",
      "Epoch 64/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0056 - acc: 0.9946\n",
      "Epoch 65/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9946\n",
      "Epoch 66/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0048 - acc: 0.9959\n",
      "Epoch 67/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9973\n",
      "Epoch 68/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0053 - acc: 0.9959\n",
      "Epoch 69/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0049 - acc: 0.9973\n",
      "Epoch 70/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9946\n",
      "Epoch 71/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0052 - acc: 0.9959\n",
      "Epoch 72/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0053 - acc: 0.9959\n",
      "Epoch 73/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 74/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9959\n",
      "Epoch 75/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0052 - acc: 0.9959\n",
      "Epoch 76/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 77/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0053 - acc: 0.9973\n",
      "Epoch 78/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9946\n",
      "Epoch 79/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0051 - acc: 0.9946\n",
      "Epoch 80/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 81/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9946\n",
      "Epoch 82/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0046 - acc: 0.9973\n",
      "Epoch 83/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 84/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0050 - acc: 0.9959\n",
      "Epoch 85/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 86/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 87/100\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 88/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9946\n",
      "Epoch 89/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0045 - acc: 0.9973\n",
      "Epoch 90/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0051 - acc: 0.9959\n",
      "Epoch 91/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0050 - acc: 0.9973\n",
      "Epoch 92/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0050 - acc: 0.9946\n",
      "Epoch 93/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0055 - acc: 0.9973\n",
      "Epoch 94/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9973\n",
      "Epoch 95/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0052 - acc: 0.9946\n",
      "Epoch 96/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0047 - acc: 0.9973\n",
      "Epoch 97/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0049 - acc: 0.9959\n",
      "Epoch 98/100\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.0049 - acc: 0.9959\n",
      "Epoch 99/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0049 - acc: 0.9959\n",
      "Epoch 100/100\n",
      "736/736 [==============================] - 0s 127us/step - loss: 0.0049 - acc: 0.9946\n"
     ]
    }
   ],
   "source": [
    "seed(0)\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim =  32, input_shape = (X_train.shape[1],),activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 32, activation = 'relu'))\n",
    "model.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adagrad', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = 100, epochs = 100)\n",
    "y_pred = model.predict(X_test).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = labelEncoder.inverse_transform(df['Keras_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Keras'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'.\\Desktop\\train_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
